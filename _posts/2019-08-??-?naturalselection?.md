---
layout: post
mathjax: true
title: NaturalSelection: a simple way to evolve neural networks
---

Hyperparameters can seem like one of the big black boxes when building neural networks: how many neurons do we need, how much dropout? What about batch size? Activations? Initialisation? Optimiser? At this point not much is known about how to make educated choices for these based on the data, and it seems that most people resort to making random guesses: either systematically through random search
